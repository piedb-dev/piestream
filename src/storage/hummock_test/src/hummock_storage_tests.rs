// Copyright 2022 PieDb Data
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

use std::ops::Bound::{Included, Unbounded};
use std::sync::Arc;

use bytes::Bytes;
use parking_lot::RwLock;
use piestream_hummock_sdk::HummockReadEpoch;
use piestream_meta::hummock::test_utils::setup_compute_env;
use piestream_meta::hummock::MockHummockMetaClient;
use piestream_rpc_client::HummockMetaClient;
use piestream_storage::hummock::event_handler::HummockEventHandler;
use piestream_storage::hummock::iterator::test_utils::mock_sstable_store;
use piestream_storage::hummock::local_version::local_version_manager::LocalVersionManager;
use piestream_storage::hummock::store::state_store::HummockStorage;
use piestream_storage::hummock::store::version::HummockReadVersion;
use piestream_storage::hummock::store::{ReadOptions, StateStore};
use piestream_storage::hummock::test_utils::default_config_for_test;
use piestream_storage::storage_value::StorageValue;
use piestream_storage::store::WriteOptions;
use piestream_storage::StateStoreIter;

use crate::test_utils::prepare_local_version_manager_new;

async fn try_wait_epoch_for_test(wait_epoch: u64, uploader: Arc<LocalVersionManager>) {
    uploader
        .try_wait_epoch(HummockReadEpoch::Committed(wait_epoch))
        .await
        .unwrap()
}

#[tokio::test]
async fn test_storage_basic() {
    let sstable_store = mock_sstable_store();
    let hummock_options = Arc::new(default_config_for_test());
    let (env, hummock_manager_ref, _cluster_manager_ref, worker_node) =
        setup_compute_env(8080).await;
    let hummock_meta_client = Arc::new(MockHummockMetaClient::new(
        hummock_manager_ref.clone(),
        worker_node.id,
    ));

    let (uploader, event_tx, event_rx) = prepare_local_version_manager_new(
        hummock_options.clone(),
        env,
        hummock_manager_ref,
        worker_node,
        sstable_store.clone(),
    )
    .await;

    let read_version = Arc::new(RwLock::new(HummockReadVersion::new(
        uploader.get_pinned_version(),
    )));

    tokio::spawn(
        HummockEventHandler::new(uploader.clone(), event_rx, read_version.clone())
            .start_hummock_event_handler_worker(),
    );

    let hummock_storage = HummockStorage::for_test(
        hummock_options,
        sstable_store,
        hummock_meta_client.clone(),
        read_version,
        event_tx,
    )
    .unwrap();

    // First batch inserts the anchor and others.
    let mut batch1 = vec![
        (Bytes::from("aa"), StorageValue::new_put("111")),
        (Bytes::from("bb"), StorageValue::new_put("222")),
    ];

    // Make sure the batch is sorted.
    batch1.sort_by(|(k1, _), (k2, _)| k1.cmp(k2));

    // Second batch modifies the anchor.
    let mut batch2 = vec![
        (Bytes::from("cc"), StorageValue::new_put("333")),
        (Bytes::from("aa"), StorageValue::new_put("111111")),
    ];

    // Make sure the batch is sorted.
    batch2.sort_by(|(k1, _), (k2, _)| k1.cmp(k2));

    // Third batch deletes the anchor
    let mut batch3 = vec![
        (Bytes::from("dd"), StorageValue::new_put("444")),
        (Bytes::from("ee"), StorageValue::new_put("555")),
        (Bytes::from("aa"), StorageValue::new_delete()),
    ];

    // Make sure the batch is sorted.
    batch3.sort_by(|(k1, _), (k2, _)| k1.cmp(k2));

    // epoch 0 is reserved by storage service
    let epoch1: u64 = 1;

    // Write the first batch.
    hummock_storage
        .ingest_batch(
            batch1,
            WriteOptions {
                epoch: epoch1,
                table_id: Default::default(),
            },
        )
        .await
        .unwrap();

    // Get the value after flushing to remote.
    let value = hummock_storage
        .get(
            &Bytes::from("aa"),
            epoch1,
            ReadOptions {
                table_id: Default::default(),
                retention_seconds: None,
                check_bloom_filter: true,
                prefix_hint: None,
            },
        )
        .await
        .unwrap()
        .unwrap();
    assert_eq!(value, Bytes::from("111"));
    let value = hummock_storage
        .get(
            &Bytes::from("bb"),
            epoch1,
            ReadOptions {
                table_id: Default::default(),
                retention_seconds: None,
                check_bloom_filter: true,
                prefix_hint: None,
            },
        )
        .await
        .unwrap()
        .unwrap();
    assert_eq!(value, Bytes::from("222"));

    // Test looking for a nonexistent key. `next()` would return the next key.
    let value = hummock_storage
        .get(
            &Bytes::from("ab"),
            epoch1,
            ReadOptions {
                table_id: Default::default(),
                retention_seconds: None,
                check_bloom_filter: true,
                prefix_hint: None,
            },
        )
        .await
        .unwrap();
    assert_eq!(value, None);

    let epoch2 = epoch1 + 1;
    hummock_storage
        .ingest_batch(
            batch2,
            WriteOptions {
                epoch: epoch2,
                table_id: Default::default(),
            },
        )
        .await
        .unwrap();

    // Get the value after flushing to remote.
    let value = hummock_storage
        .get(
            &Bytes::from("aa"),
            epoch2,
            ReadOptions {
                table_id: Default::default(),
                retention_seconds: None,
                check_bloom_filter: true,
                prefix_hint: None,
            },
        )
        .await
        .unwrap()
        .unwrap();
    assert_eq!(value, Bytes::from("111111"));

    // Write the third batch.
    let epoch3 = epoch2 + 1;
    hummock_storage
        .ingest_batch(
            batch3,
            WriteOptions {
                epoch: epoch3,
                table_id: Default::default(),
            },
        )
        .await
        .unwrap();

    // Get the value after flushing to remote.
    let value = hummock_storage
        .get(
            &Bytes::from("aa"),
            epoch3,
            ReadOptions {
                table_id: Default::default(),
                retention_seconds: None,
                check_bloom_filter: true,
                prefix_hint: None,
            },
        )
        .await
        .unwrap();
    assert_eq!(value, None);

    // Get non-existent maximum key.
    let value = hummock_storage
        .get(
            &Bytes::from("ff"),
            epoch3,
            ReadOptions {
                table_id: Default::default(),
                retention_seconds: None,
                check_bloom_filter: true,
                prefix_hint: None,
            },
        )
        .await
        .unwrap();
    assert_eq!(value, None);

    // Write aa bb
    let mut iter = hummock_storage
        .iter(
            (Unbounded, Included(b"ee".to_vec())),
            epoch1,
            ReadOptions {
                table_id: Default::default(),
                retention_seconds: None,
                check_bloom_filter: true,
                prefix_hint: None,
            },
        )
        .await
        .unwrap();
    assert_eq!(
        Some((
            Bytes::copy_from_slice(&b"aa"[..]),
            Bytes::copy_from_slice(&b"111"[..])
        )),
        iter.next().await.unwrap()
    );
    assert_eq!(
        Some((
            Bytes::copy_from_slice(&b"bb"[..]),
            Bytes::copy_from_slice(&b"222"[..])
        )),
        iter.next().await.unwrap()
    );
    assert_eq!(None, iter.next().await.unwrap());

    // Get the anchor value at the first snapshot
    let value = hummock_storage
        .get(
            &Bytes::from("aa"),
            epoch1,
            ReadOptions {
                table_id: Default::default(),
                retention_seconds: None,
                check_bloom_filter: true,
                prefix_hint: None,
            },
        )
        .await
        .unwrap()
        .unwrap();
    assert_eq!(value, Bytes::from("111"));

    // Get the anchor value at the second snapshot
    let value = hummock_storage
        .get(
            &Bytes::from("aa"),
            epoch2,
            ReadOptions {
                table_id: Default::default(),
                retention_seconds: None,
                check_bloom_filter: true,
                prefix_hint: None,
            },
        )
        .await
        .unwrap()
        .unwrap();
    assert_eq!(value, Bytes::from("111111"));
    // Update aa, write cc
    let mut iter = hummock_storage
        .iter(
            (Unbounded, Included(b"ee".to_vec())),
            epoch2,
            ReadOptions {
                table_id: Default::default(),
                retention_seconds: None,
                check_bloom_filter: true,
                prefix_hint: None,
            },
        )
        .await
        .unwrap();
    assert_eq!(
        Some((
            Bytes::copy_from_slice(&b"aa"[..]),
            Bytes::copy_from_slice(&b"111111"[..])
        )),
        iter.next().await.unwrap()
    );
    assert_eq!(
        Some((
            Bytes::copy_from_slice(&b"bb"[..]),
            Bytes::copy_from_slice(&b"222"[..])
        )),
        iter.next().await.unwrap()
    );
    assert_eq!(
        Some((
            Bytes::copy_from_slice(&b"cc"[..]),
            Bytes::copy_from_slice(&b"333"[..])
        )),
        iter.next().await.unwrap()
    );
    assert_eq!(None, iter.next().await.unwrap());

    // Delete aa, write dd,ee
    let mut iter = hummock_storage
        .iter(
            (Unbounded, Included(b"ee".to_vec())),
            epoch3,
            ReadOptions {
                table_id: Default::default(),
                retention_seconds: None,
                check_bloom_filter: true,
                prefix_hint: None,
            },
        )
        .await
        .unwrap();
    assert_eq!(
        Some((
            Bytes::copy_from_slice(&b"bb"[..]),
            Bytes::copy_from_slice(&b"222"[..])
        )),
        iter.next().await.unwrap()
    );
    assert_eq!(
        Some((
            Bytes::copy_from_slice(&b"cc"[..]),
            Bytes::copy_from_slice(&b"333"[..])
        )),
        iter.next().await.unwrap()
    );
    assert_eq!(
        Some((
            Bytes::copy_from_slice(&b"dd"[..]),
            Bytes::copy_from_slice(&b"444"[..])
        )),
        iter.next().await.unwrap()
    );
    assert_eq!(
        Some((
            Bytes::copy_from_slice(&b"ee"[..]),
            Bytes::copy_from_slice(&b"555"[..])
        )),
        iter.next().await.unwrap()
    );
    assert_eq!(None, iter.next().await.unwrap());

    // TODO: add more test cases after sync is supported
}

#[tokio::test]
async fn test_state_store_sync() {
    let sstable_store = mock_sstable_store();
    let hummock_options = Arc::new(default_config_for_test());
    let (env, hummock_manager_ref, _cluster_manager_ref, worker_node) =
        setup_compute_env(8080).await;
    let hummock_meta_client = Arc::new(MockHummockMetaClient::new(
        hummock_manager_ref.clone(),
        worker_node.id,
    ));

    let (uploader, event_tx, event_rx) = prepare_local_version_manager_new(
        hummock_options.clone(),
        env,
        hummock_manager_ref,
        worker_node,
        sstable_store.clone(),
    )
    .await;

    let read_version = Arc::new(RwLock::new(HummockReadVersion::new(
        uploader.get_pinned_version(),
    )));

    tokio::spawn(
        HummockEventHandler::new(uploader.clone(), event_rx, read_version.clone())
            .start_hummock_event_handler_worker(),
    );

    let hummock_storage = HummockStorage::for_test(
        hummock_options,
        sstable_store,
        hummock_meta_client.clone(),
        read_version,
        event_tx,
    )
    .unwrap();

    let epoch1: _ = uploader.get_pinned_version().max_committed_epoch() + 1;

    // ingest 16B batch
    let mut batch1 = vec![
        (Bytes::from("aaaa"), StorageValue::new_put("1111")),
        (Bytes::from("bbbb"), StorageValue::new_put("2222")),
    ];

    // Make sure the batch is sorted.
    batch1.sort_by(|(k1, _), (k2, _)| k1.cmp(k2));
    hummock_storage
        .ingest_batch(
            batch1,
            WriteOptions {
                epoch: epoch1,
                table_id: Default::default(),
            },
        )
        .await
        .unwrap();

    // ingest 24B batch
    let mut batch2 = vec![
        (Bytes::from("cccc"), StorageValue::new_put("3333")),
        (Bytes::from("dddd"), StorageValue::new_put("4444")),
        (Bytes::from("eeee"), StorageValue::new_put("5555")),
    ];
    batch2.sort_by(|(k1, _), (k2, _)| k1.cmp(k2));
    hummock_storage
        .ingest_batch(
            batch2,
            WriteOptions {
                epoch: epoch1,
                table_id: Default::default(),
            },
        )
        .await
        .unwrap();

    let epoch2 = epoch1 + 1;

    // ingest more 8B then will trigger a sync behind the scene
    let mut batch3 = vec![(Bytes::from("eeee"), StorageValue::new_put("6666"))];
    batch3.sort_by(|(k1, _), (k2, _)| k1.cmp(k2));
    hummock_storage
        .ingest_batch(
            batch3,
            WriteOptions {
                epoch: epoch2,
                table_id: Default::default(),
            },
        )
        .await
        .unwrap();

    let ssts = uploader
        .sync_shared_buffer(epoch1)
        .await
        .unwrap()
        .uncommitted_ssts;
    hummock_meta_client
        .commit_epoch(epoch1, ssts)
        .await
        .unwrap();
    try_wait_epoch_for_test(epoch1, uploader.clone()).await;
    {
        // after sync 1 epoch
        let read_version = hummock_storage.read_version();
        assert_eq!(1, read_version.read().staging().imm.len());
        assert!(read_version.read().staging().sst.is_empty());
    }

    {
        let kv_map = [
            ("aaaa", "1111"),
            ("bbbb", "2222"),
            ("cccc", "3333"),
            ("dddd", "4444"),
            ("eeee", "5555"),
        ];

        for (k, v) in kv_map {
            let value = hummock_storage
                .get(
                    k.as_bytes(),
                    epoch1,
                    ReadOptions {
                        table_id: Default::default(),
                        retention_seconds: None,
                        check_bloom_filter: true,
                        prefix_hint: None,
                    },
                )
                .await
                .unwrap()
                .unwrap();
            assert_eq!(value, Bytes::from(v));
        }
    }

    let ssts = uploader
        .sync_shared_buffer(epoch2)
        .await
        .unwrap()
        .uncommitted_ssts;

    hummock_meta_client
        .commit_epoch(epoch2, ssts)
        .await
        .unwrap();
    try_wait_epoch_for_test(epoch2, uploader.clone()).await;
    {
        // after sync all epoch
        let read_version = hummock_storage.read_version();
        assert!(read_version.read().staging().imm.is_empty());
        assert!(read_version.read().staging().sst.is_empty());
    }

    {
        let kv_map = [
            ("aaaa", "1111"),
            ("bbbb", "2222"),
            ("cccc", "3333"),
            ("dddd", "4444"),
            ("eeee", "6666"),
        ];

        for (k, v) in kv_map {
            let value = hummock_storage
                .get(
                    k.as_bytes(),
                    epoch2,
                    ReadOptions {
                        table_id: Default::default(),
                        retention_seconds: None,
                        check_bloom_filter: true,
                        prefix_hint: None,
                    },
                )
                .await
                .unwrap()
                .unwrap();
            assert_eq!(value, Bytes::from(v));
        }
    }

    // test iter
    {
        let mut iter = hummock_storage
            .iter(
                (Unbounded, Included(b"eeee".to_vec())),
                epoch1,
                ReadOptions {
                    table_id: Default::default(),
                    retention_seconds: None,
                    check_bloom_filter: true,
                    prefix_hint: None,
                },
            )
            .await
            .unwrap();

        let kv_map = [
            ("aaaa", "1111"),
            ("bbbb", "2222"),
            ("cccc", "3333"),
            ("dddd", "4444"),
            ("eeee", "5555"),
        ];

        for (k, v) in kv_map {
            let result = iter.next().await.unwrap();
            assert_eq!(result, Some((Bytes::from(k), Bytes::from(v))));
        }

        assert!(iter.next().await.unwrap().is_none());
    }

    {
        let mut iter = hummock_storage
            .iter(
                (Unbounded, Included(b"eeee".to_vec())),
                epoch2,
                ReadOptions {
                    table_id: Default::default(),
                    retention_seconds: None,
                    check_bloom_filter: true,
                    prefix_hint: None,
                },
            )
            .await
            .unwrap();

        let kv_map = [
            ("aaaa", "1111"),
            ("bbbb", "2222"),
            ("cccc", "3333"),
            ("dddd", "4444"),
            ("eeee", "6666"),
        ];

        for (k, v) in kv_map {
            let result = iter.next().await.unwrap();
            assert_eq!(result, Some((Bytes::from(k), Bytes::from(v))));
        }
    }
}

#[tokio::test]
async fn test_delete_get() {
    let sstable_store = mock_sstable_store();
    let hummock_options = Arc::new(default_config_for_test());
    let (env, hummock_manager_ref, _cluster_manager_ref, worker_node) =
        setup_compute_env(8080).await;
    let hummock_meta_client = Arc::new(MockHummockMetaClient::new(
        hummock_manager_ref.clone(),
        worker_node.id,
    ));

    let (uploader, event_tx, event_rx) = prepare_local_version_manager_new(
        hummock_options.clone(),
        env,
        hummock_manager_ref,
        worker_node,
        sstable_store.clone(),
    )
    .await;

    let read_version = Arc::new(RwLock::new(HummockReadVersion::new(
        uploader.get_pinned_version(),
    )));

    tokio::spawn(
        HummockEventHandler::new(uploader.clone(), event_rx, read_version.clone())
            .start_hummock_event_handler_worker(),
    );

    let hummock_storage = HummockStorage::for_test(
        hummock_options,
        sstable_store,
        hummock_meta_client.clone(),
        read_version,
        event_tx,
    )
    .unwrap();

    let initial_epoch = uploader.get_pinned_version().max_committed_epoch();
    let epoch1 = initial_epoch + 1;
    let batch1 = vec![
        (Bytes::from("aa"), StorageValue::new_put("111")),
        (Bytes::from("bb"), StorageValue::new_put("222")),
    ];
    hummock_storage
        .ingest_batch(
            batch1,
            WriteOptions {
                epoch: epoch1,
                table_id: Default::default(),
            },
        )
        .await
        .unwrap();
    let ssts = uploader
        .sync_shared_buffer(epoch1)
        .await
        .unwrap()
        .uncommitted_ssts;
    hummock_meta_client
        .commit_epoch(epoch1, ssts)
        .await
        .unwrap();
    let epoch2 = initial_epoch + 2;
    let batch2 = vec![(Bytes::from("bb"), StorageValue::new_delete())];
    hummock_storage
        .ingest_batch(
            batch2,
            WriteOptions {
                epoch: epoch2,
                table_id: Default::default(),
            },
        )
        .await
        .unwrap();
    let ssts = uploader
        .sync_shared_buffer(epoch2)
        .await
        .unwrap()
        .uncommitted_ssts;
    hummock_meta_client
        .commit_epoch(epoch2, ssts)
        .await
        .unwrap();

    try_wait_epoch_for_test(epoch2, uploader.clone()).await;
    assert!(hummock_storage
        .get(
            "bb".as_bytes(),
            epoch2,
            ReadOptions {
                prefix_hint: None,
                check_bloom_filter: true,
                table_id: Default::default(),
                retention_seconds: None,
            }
        )
        .await
        .unwrap()
        .is_none());
}

#[tokio::test]
async fn test_multiple_epoch_sync() {
    let sstable_store = mock_sstable_store();
    let hummock_options = Arc::new(default_config_for_test());
    let (env, hummock_manager_ref, _cluster_manager_ref, worker_node) =
        setup_compute_env(8080).await;
    let hummock_meta_client = Arc::new(MockHummockMetaClient::new(
        hummock_manager_ref.clone(),
        worker_node.id,
    ));

    let (uploader, event_tx, event_rx) = prepare_local_version_manager_new(
        hummock_options.clone(),
        env,
        hummock_manager_ref,
        worker_node,
        sstable_store.clone(),
    )
    .await;

    let read_version = Arc::new(RwLock::new(HummockReadVersion::new(
        uploader.get_pinned_version(),
    )));

    tokio::spawn(
        HummockEventHandler::new(uploader.clone(), event_rx, read_version.clone())
            .start_hummock_event_handler_worker(),
    );

    let hummock_storage = HummockStorage::for_test(
        hummock_options,
        sstable_store,
        hummock_meta_client.clone(),
        read_version,
        event_tx,
    )
    .unwrap();

    let initial_epoch = uploader.get_pinned_version().max_committed_epoch();
    let epoch1 = initial_epoch + 1;
    let batch1 = vec![
        (Bytes::from("aa"), StorageValue::new_put("111")),
        (Bytes::from("bb"), StorageValue::new_put("222")),
    ];
    hummock_storage
        .ingest_batch(
            batch1,
            WriteOptions {
                epoch: epoch1,
                table_id: Default::default(),
            },
        )
        .await
        .unwrap();

    let epoch2 = initial_epoch + 2;
    let batch2 = vec![(Bytes::from("bb"), StorageValue::new_delete())];
    hummock_storage
        .ingest_batch(
            batch2,
            WriteOptions {
                epoch: epoch2,
                table_id: Default::default(),
            },
        )
        .await
        .unwrap();

    let epoch3 = initial_epoch + 3;
    let batch3 = vec![
        (Bytes::from("aa"), StorageValue::new_put("444")),
        (Bytes::from("bb"), StorageValue::new_put("555")),
    ];
    hummock_storage
        .ingest_batch(
            batch3,
            WriteOptions {
                epoch: epoch3,
                table_id: Default::default(),
            },
        )
        .await
        .unwrap();
    let test_get = || {
        let hummock_storage_clone = hummock_storage.clone();
        async move {
            assert_eq!(
                hummock_storage_clone
                    .get(
                        "bb".as_bytes(),
                        epoch1,
                        ReadOptions {
                            table_id: Default::default(),
                            retention_seconds: None,
                            check_bloom_filter: true,
                            prefix_hint: None,
                        },
                    )
                    .await
                    .unwrap()
                    .unwrap(),
                "222".as_bytes()
            );
            assert!(hummock_storage_clone
                .get(
                    "bb".as_bytes(),
                    epoch2,
                    ReadOptions {
                        table_id: Default::default(),
                        retention_seconds: None,
                        check_bloom_filter: true,
                        prefix_hint: None,
                    },
                )
                .await
                .unwrap()
                .is_none());
            assert_eq!(
                hummock_storage_clone
                    .get(
                        "bb".as_bytes(),
                        epoch3,
                        ReadOptions {
                            table_id: Default::default(),
                            retention_seconds: None,
                            check_bloom_filter: true,
                            prefix_hint: None,
                        },
                    )
                    .await
                    .unwrap()
                    .unwrap(),
                "555".as_bytes()
            );
        }
    };
    test_get().await;
    let sync_result2 = uploader.sync_shared_buffer(epoch2).await.unwrap();
    let sync_result3 = uploader.sync_shared_buffer(epoch3).await.unwrap();
    test_get().await;
    hummock_meta_client
        .commit_epoch(epoch2, sync_result2.uncommitted_ssts)
        .await
        .unwrap();
    hummock_meta_client
        .commit_epoch(epoch3, sync_result3.uncommitted_ssts)
        .await
        .unwrap();

    try_wait_epoch_for_test(epoch3, uploader.clone()).await;
    test_get().await;
}
